{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import Chain\n",
    "from chainer import optimizers\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import datasets, iterators, training\n",
    "from chainer.training import extensions\n",
    "import numpy as np\n",
    "\n",
    "class MLP(Chain):\n",
    "       def __init__(self, n_units, n_out):\n",
    "           super(MLP, self).__init__()\n",
    "           with self.init_scope():\n",
    "               self.l1 = L.Linear(None, n_units)\n",
    "               self.l2 = L.Linear(None, n_units)\n",
    "               self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "       def __call__(self, x):\n",
    "           h1 = F.relu(self.l1(x))\n",
    "           h2 = F.relu(self.l2(h1))\n",
    "           y = self.l3(h2)\n",
    "           return y\n",
    "\n",
    "model = L.Classifier(MLP(1000, 10)).to_gpu(0)  # to_gpu returns itself\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(70000, 784).astype(np.float32)\n",
    "target = np.random.randint(10, size=70000).astype(np.int32)\n",
    "train = datasets.TupleDataset(data[:60000], target[:60000])\n",
    "test = datasets.TupleDataset(data[60000:], target[60000:])\n",
    "train_iter = iterators.SerialIterator(train, batch_size=100)\n",
    "test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = training.StandardUpdater(train_iter, optimizer, device=0)\n",
    "trainer = training.Trainer(updater, (2, 'epoch'), out='result')\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=0))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           2.31142     0.0996167      2.30854               0.1008                    2.32828       \n",
      "\u001b[J2           2.30469     0.108917       2.30894               0.1017                    5.5287        \n",
      "\u001b[J3           2.30018     0.113883       2.30882               0.098                     8.81808       \n",
      "\u001b[J4           2.29676     0.117917       2.31011               0.0953                    12.0916       \n",
      "\u001b[J5           2.29374     0.124283       2.30883               0.0986                    15.3748       \n",
      "\u001b[J6           2.29069     0.127233       2.31013               0.0978                    18.6656       \n",
      "\u001b[J7           2.28783     0.133083       2.31051               0.0916                    22.1075       \n",
      "\u001b[J8           2.28527     0.13835        2.31102               0.0991                    25.3902       \n",
      "\u001b[J9           2.28226     0.141167       2.31398               0.0947                    28.8479       \n",
      "\u001b[J10          2.27888     0.14455        2.31428               0.1001                    32.0999       \n",
      "\u001b[J11          2.27618     0.14855        2.31446               0.096                     35.362        \n",
      "\u001b[J12          2.27346     0.150517       2.31544               0.0992                    38.6582       \n",
      "\u001b[J13          2.27038     0.154683       2.31779               0.098                     41.8921       \n",
      "\u001b[J14          2.26715     0.156517       2.31917               0.0996                    45.1169       \n",
      "\u001b[J15          2.26406     0.1591         2.31879               0.0978                    48.4049       \n",
      "\u001b[J16          2.26079     0.1631         2.32367               0.0997                    51.6935       \n",
      "\u001b[J17          2.2573      0.166017       2.32561               0.0962                    54.9159       \n",
      "\u001b[J18          2.25366     0.168933       2.32887               0.0998                    58.1862       \n",
      "\u001b[J19          2.24974     0.171883       2.33041               0.0934                    61.5103       \n",
      "\u001b[J20          2.24639     0.174183       2.33092               0.0998                    64.7775       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Without gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import Chain\n",
    "from chainer import optimizers\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import datasets, iterators, training\n",
    "from chainer.training import extensions\n",
    "import numpy as np\n",
    "\n",
    "class MLP(Chain):\n",
    "       def __init__(self, n_units, n_out):\n",
    "           super(MLP, self).__init__()\n",
    "           with self.init_scope():\n",
    "               self.l1 = L.Linear(None, n_units)\n",
    "               self.l2 = L.Linear(None, n_units)\n",
    "               self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "       def __call__(self, x):\n",
    "           h1 = F.relu(self.l1(x))\n",
    "           h2 = F.relu(self.l2(h1))\n",
    "           y = self.l3(h2)\n",
    "           return y\n",
    "\n",
    "model = L.Classifier(MLP(1000, 10)).to_gpu(0)  # to_gpu returns itself\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(70000, 784).astype(np.float32)\n",
    "target = np.random.randint(10, size=70000).astype(np.int32)\n",
    "train = datasets.TupleDataset(data[:60000], target[:60000])\n",
    "test = datasets.TupleDataset(data[60000:], target[60000:])\n",
    "train_iter = iterators.SerialIterator(train, batch_size=100)\n",
    "test_iter = iterators.SerialIterator(test, batch_size=100, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           2.31153     0.0991667      2.30918               0.0984                    2.3201        \n",
      "\u001b[J2           2.30496     0.105717       2.30761               0.102                     5.5385        \n"
     ]
    }
   ],
   "source": [
    "updater = training.StandardUpdater(train_iter, optimizer, device=0)\n",
    "trainer = training.Trainer(updater, (2, 'epoch'), out='result')\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=0))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
